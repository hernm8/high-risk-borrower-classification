{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb068707-12c7-40d7-a432-788056c6e73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (396030, 28)\n",
      "Working shape: (50000, 28)\n",
      "Nulls (top 10):\n",
      "mort_acc                4794\n",
      "emp_title               2912\n",
      "emp_length              2318\n",
      "title                    210\n",
      "pub_rec_bankruptcies      55\n",
      "revol_util                43\n",
      "dti                        0\n",
      "address                    0\n",
      "application_type           0\n",
      "initial_list_status        0\n",
      "dtype: int64\n",
      "\n",
      "Target definition:\n",
      "  LOW RISK  (high_risk=0) = grades A, B, C\n",
      "  HIGH RISK (high_risk=1) = grades D, E, F, G\n",
      "High-risk rate: 0.27734\n",
      "Counts: {0: 36133, 1: 13867}\n",
      "\n",
      "Selected feature count: 17\n",
      "X shape: (50000, 17) | y shape: (50000,)\n",
      "\n",
      "After cleaning:\n",
      "X dtypes summary:\n",
      "int64      6\n",
      "float64    6\n",
      "object     5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After feature engineering:\n",
      "X shape: (50000, 24)\n",
      "Train rate: 0.2774 | Test rate: 0.2773\n",
      "Train shape: (40000, 24) | Test shape: (10000, 24)\n",
      "\n",
      "Numeric cols: 19 | Categorical cols: 5\n",
      "\n",
      "==============================================================================\n",
      "STEP 10 — MODEL RESULTS: LogisticRegression\n",
      "==============================================================================\n",
      "ROC-AUC: 0.8945\n",
      "Best threshold: 0.6\n",
      "LOW RISK (0):  precision=0.887, recall=0.888\n",
      "HIGH RISK (1): precision=0.707, recall=0.704\n",
      "Objective = min(p0,r0,p1,r1): 0.704\n",
      "PASS 50/50 rubric?: True\n",
      "Confusion Matrix:\n",
      " [[6419  808]\n",
      " [ 821 1952]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      7227\n",
      "           1       0.71      0.70      0.71      2773\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "\n",
      "==============================================================================\n",
      "STEP 10 — MODEL RESULTS: KNN\n",
      "==============================================================================\n",
      "ROC-AUC: 0.7998\n",
      "Best threshold: 0.31\n",
      "LOW RISK (0):  precision=0.842, recall=0.838\n",
      "HIGH RISK (1): precision=0.584, recall=0.591\n",
      "Objective = min(p0,r0,p1,r1): 0.584\n",
      "PASS 50/50 rubric?: True\n",
      "Confusion Matrix:\n",
      " [[6059 1168]\n",
      " [1135 1638]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      7227\n",
      "           1       0.58      0.59      0.59      2773\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n",
      "\n",
      "==============================================================================\n",
      "STEP 10 — MODEL RESULTS: RandomForest\n",
      "==============================================================================\n",
      "ROC-AUC: 0.8825\n",
      "Best threshold: 0.35\n",
      "LOW RISK (0):  precision=0.880, recall=0.878\n",
      "HIGH RISK (1): precision=0.684, recall=0.688\n",
      "Objective = min(p0,r0,p1,r1): 0.684\n",
      "PASS 50/50 rubric?: True\n",
      "Confusion Matrix:\n",
      " [[6346  881]\n",
      " [ 865 1908]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      7227\n",
      "           1       0.68      0.69      0.69      2773\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.78      0.78      0.78     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "==============================================================================\n",
      "STEP 10 — MODEL RESULTS: SVC (Calibrated LinearSVC)\n",
      "==============================================================================\n",
      "ROC-AUC: 0.8916\n",
      "Best threshold: 0.37\n",
      "LOW RISK (0):  precision=0.885, recall=0.885\n",
      "HIGH RISK (1): precision=0.701, recall=0.700\n",
      "Objective = min(p0,r0,p1,r1): 0.7\n",
      "PASS 50/50 rubric?: True\n",
      "Confusion Matrix:\n",
      " [[6399  828]\n",
      " [ 832 1941]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      7227\n",
      "           1       0.70      0.70      0.70      2773\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "##############################################################################\n",
      "FINAL COMPARISON (PASS first, then objective, then AUC)\n",
      "##############################################################################\n",
      "                     model    auc  thr    p0    r0    p1    r1  objective  pass_50_50\n",
      "        LogisticRegression 0.8945 0.60 0.887 0.888 0.707 0.704      0.704        True\n",
      "SVC (Calibrated LinearSVC) 0.8916 0.37 0.885 0.885 0.701 0.700      0.700        True\n",
      "              RandomForest 0.8825 0.35 0.880 0.878 0.684 0.688      0.684        True\n",
      "                       KNN 0.7998 0.31 0.842 0.838 0.584 0.591      0.584        True\n",
      "\n",
      "WINNER: LogisticRegression\n",
      "Winner threshold: 0.6\n",
      "Winner PASS 50/50?: True\n",
      "\n",
      "Sample prediction outputs (winner):\n",
      "        pred_prob_high_risk  pred_high_risk  actual_high_risk\n",
      "308311             0.069291               0                 0\n",
      "154636             0.504178               0                 0\n",
      "206533             0.024279               0                 0\n",
      "394926             0.354578               0                 0\n",
      "316669             0.998502               1                 1\n",
      "77338              0.905976               1                 1\n",
      "362368             0.019052               0                 0\n",
      "317489             0.649369               1                 0\n",
      "10486              0.964311               1                 1\n",
      "235912             0.278710               0                 1\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# NOTEBOOK: HIGH-RISK LOAN PREDICTION (Binary) + INCOME FEATURES\n",
    "# DATA: lending_club_clean.csv\n",
    "# GOAL: Precision >= 0.50 AND Recall >= 0.50 for BOTH classes\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 0 — IMPORT LIBRARIES + SETTINGS\n",
    "# Purpose: Load all packages used in this notebook and set key config values\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1 — CONFIGURATION (EDIT PATH ONLY)\n",
    "# Purpose: Control file path, sample size, random seed, and thresholds\n",
    "# ============================================================\n",
    "\n",
    "file_path = r\"C:\\Users\\mikeh\\Downloads\\lending_club_clean.csv\"\n",
    "\n",
    "USE_FULL_DATA = False\n",
    "N = 50_000\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "THRESHOLDS = np.round(np.arange(0.05, 0.95, 0.01), 2)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2 — LOAD DATA + BASIC HEALTH CHECKS\n",
    "# Purpose: Load CSV, confirm required columns exist, optionally downsample\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "required_cols = {\"grade\", \"annual_inc\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "assert not missing, f\"Missing required columns: {missing}\"\n",
    "\n",
    "# Optional sample for speed (keeps grade mix stable)\n",
    "if (not USE_FULL_DATA) and (len(df) > N):\n",
    "    df, _ = train_test_split(\n",
    "        df,\n",
    "        train_size=N,\n",
    "        stratify=df[\"grade\"],\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "print(\"Working shape:\", df.shape)\n",
    "print(\"Nulls (top 10):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3 — DEFINE TARGET (GROUND TRUTH)\n",
    "# Purpose: Create the binary target high_risk from the grade column\n",
    "# ============================================================\n",
    "\n",
    "df[\"high_risk\"] = df[\"grade\"].isin([\"D\", \"E\", \"F\", \"G\"]).astype(int)\n",
    "\n",
    "print(\"\\nTarget definition:\")\n",
    "print(\"  LOW RISK  (high_risk=0) = grades A, B, C\")\n",
    "print(\"  HIGH RISK (high_risk=1) = grades D, E, F, G\")\n",
    "print(\"High-risk rate:\", round(df[\"high_risk\"].mean(), 5))\n",
    "print(\"Counts:\", df[\"high_risk\"].value_counts().to_dict())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4 — SELECT FEATURES (NO LEAKAGE)\n",
    "# Purpose: Choose the columns used as predictors and create X and y\n",
    "# ============================================================\n",
    "\n",
    "base_features = [\n",
    "    \"loan_amnt\",\n",
    "    \"term\",\n",
    "    \"emp_length\",\n",
    "    \"home_ownership\",\n",
    "    \"annual_inc\",\n",
    "    \"verification_status\",\n",
    "    \"purpose\",\n",
    "    \"dti\",\n",
    "    \"open_acc\",\n",
    "    \"revol_bal\",\n",
    "    \"revol_util\",\n",
    "    \"total_acc\",\n",
    "    \"application_type\",\n",
    "    \"mort_acc\",\n",
    "    \"pub_rec\",\n",
    "    \"pub_rec_bankruptcies\",\n",
    "    \"initial_list_status\"\n",
    "]\n",
    "base_features = [c for c in base_features if c in df.columns]\n",
    "\n",
    "X = df[base_features].copy()\n",
    "y = df[\"high_risk\"].astype(int).copy()\n",
    "\n",
    "print(\"\\nSelected feature count:\", len(base_features))\n",
    "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5 — CLEAN RAW FEATURE FORMATS\n",
    "# Purpose: Convert strings to numeric where needed (term, revol_util, etc.)\n",
    "# ============================================================\n",
    "\n",
    "if \"term\" in X.columns:\n",
    "    X[\"term\"] = X[\"term\"].astype(str).str.extract(r\"(\\d+)\")[0]\n",
    "    X[\"term\"] = pd.to_numeric(X[\"term\"], errors=\"coerce\")\n",
    "\n",
    "if \"revol_util\" in X.columns:\n",
    "    X[\"revol_util\"] = X[\"revol_util\"].astype(str).str.replace(\"%\", \"\", regex=False)\n",
    "    X[\"revol_util\"] = pd.to_numeric(X[\"revol_util\"], errors=\"coerce\")\n",
    "\n",
    "for col in [\"loan_amnt\",\"annual_inc\",\"dti\",\"open_acc\",\"revol_bal\",\"total_acc\",\"mort_acc\",\"pub_rec\",\"pub_rec_bankruptcies\"]:\n",
    "    if col in X.columns:\n",
    "        X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(\"X dtypes summary:\")\n",
    "print(X.dtypes.value_counts())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6 — INCOME-FOCUSED FEATURE ENGINEERING\n",
    "# Purpose: Add engineered features based on income relationships\n",
    "# ============================================================\n",
    "\n",
    "if {\"loan_amnt\",\"annual_inc\"}.issubset(X.columns):\n",
    "    X[\"loan_to_income\"] = X[\"loan_amnt\"] / (X[\"annual_inc\"] + 1.0)\n",
    "\n",
    "if \"installment\" in df.columns:\n",
    "    X[\"installment\"] = pd.to_numeric(df.loc[X.index, \"installment\"], errors=\"coerce\")\n",
    "    X[\"installment_to_income\"] = X[\"installment\"] / (X[\"annual_inc\"] + 1.0)\n",
    "\n",
    "X[\"log_income\"] = np.log1p(X[\"annual_inc\"])\n",
    "\n",
    "if {\"annual_inc\",\"open_acc\"}.issubset(X.columns):\n",
    "    X[\"income_per_account\"] = X[\"annual_inc\"] / (X[\"open_acc\"] + 1.0)\n",
    "\n",
    "if {\"annual_inc\",\"dti\"}.issubset(X.columns):\n",
    "    X[\"income_x_dti\"] = X[\"annual_inc\"] * X[\"dti\"]\n",
    "\n",
    "if {\"revol_util\",\"dti\"}.issubset(X.columns):\n",
    "    X[\"util_x_dti\"] = X[\"revol_util\"] * X[\"dti\"]\n",
    "\n",
    "print(\"\\nAfter feature engineering:\")\n",
    "print(\"X shape:\", X.shape)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 7 — TRAIN/TEST SPLIT\n",
    "# Purpose: Create training and testing sets with stable class balance\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train rate:\", round(y_train.mean(), 4), \"| Test rate:\", round(y_test.mean(), 4))\n",
    "print(\"Train shape:\", X_train.shape, \"| Test shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 8 — PREPROCESSING (IMPUTE + ENCODE + SCALE)\n",
    "# Purpose: Build a reusable preprocessor for numeric/categorical features\n",
    "# ============================================================\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "\n",
    "print(\"\\nNumeric cols:\", len(num_cols), \"| Categorical cols:\", len(cat_cols))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"sc\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 9 — HELPER FUNCTIONS (SCORING + THRESHOLD SCAN)\n",
    "# Purpose: Get probability-like scores and find the best threshold\n",
    "# ============================================================\n",
    "\n",
    "def get_scores(fitted_pipe, X_):\n",
    "    if hasattr(fitted_pipe, \"predict_proba\"):\n",
    "        return fitted_pipe.predict_proba(X_)[:, 1]\n",
    "    if hasattr(fitted_pipe, \"decision_function\"):\n",
    "        s = fitted_pipe.decision_function(X_)\n",
    "        return (s - s.min()) / (s.max() - s.min() + 1e-9)\n",
    "    return fitted_pipe.predict(X_).astype(float)\n",
    "\n",
    "def threshold_scan(y_true, scores, thresholds):\n",
    "    best = None\n",
    "    best_pass = False\n",
    "    best_obj = -1\n",
    "\n",
    "    for t in thresholds:\n",
    "        preds = (scores >= t).astype(int)\n",
    "        rep = classification_report(y_true, preds, output_dict=True, zero_division=0)\n",
    "\n",
    "        p0, r0 = rep[\"0\"][\"precision\"], rep[\"0\"][\"recall\"]\n",
    "        p1, r1 = rep[\"1\"][\"precision\"], rep[\"1\"][\"recall\"]\n",
    "\n",
    "        obj = min(p0, r0, p1, r1)\n",
    "        passed = obj >= 0.50\n",
    "\n",
    "        better = False\n",
    "        if passed and not best_pass:\n",
    "            better = True\n",
    "        elif passed and best_pass and obj > best_obj + 1e-12:\n",
    "            better = True\n",
    "        elif (not passed) and (not best_pass) and obj > best_obj + 1e-12:\n",
    "            better = True\n",
    "\n",
    "        if better:\n",
    "            best_pass = passed\n",
    "            best_obj = obj\n",
    "            best = {\n",
    "                \"threshold\": float(t),\n",
    "                \"objective\": float(obj),\n",
    "                \"passed\": bool(passed),\n",
    "                \"p0\": float(p0), \"r0\": float(r0),\n",
    "                \"p1\": float(p1), \"r1\": float(r1),\n",
    "                \"cm\": confusion_matrix(y_true, preds),\n",
    "                \"report_text\": classification_report(y_true, preds, zero_division=0)\n",
    "            }\n",
    "\n",
    "    return best\n",
    "\n",
    "def evaluate_model(model_name, estimator):\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"clf\", estimator)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    scores = get_scores(pipe, X_test)\n",
    "    auc = float(roc_auc_score(y_test, scores))\n",
    "    best = threshold_scan(y_test.values, scores, THRESHOLDS)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*78)\n",
    "    print(\"STEP 10 — MODEL RESULTS:\", model_name)\n",
    "    print(\"=\"*78)\n",
    "    print(\"ROC-AUC:\", round(auc, 4))\n",
    "    print(\"Best threshold:\", round(best[\"threshold\"], 3))\n",
    "    print(f\"LOW RISK (0):  precision={best['p0']:.3f}, recall={best['r0']:.3f}\")\n",
    "    print(f\"HIGH RISK (1): precision={best['p1']:.3f}, recall={best['r1']:.3f}\")\n",
    "    print(\"Objective = min(p0,r0,p1,r1):\", round(best[\"objective\"], 3))\n",
    "    print(\"PASS 50/50 rubric?:\", best[\"passed\"])\n",
    "    print(\"Confusion Matrix:\\n\", best[\"cm\"])\n",
    "    print(\"\\nClassification Report:\\n\", best[\"report_text\"])\n",
    "\n",
    "    row = {\n",
    "        \"model\": model_name,\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"thr\": round(best[\"threshold\"], 3),\n",
    "        \"p0\": round(best[\"p0\"], 3),\n",
    "        \"r0\": round(best[\"r0\"], 3),\n",
    "        \"p1\": round(best[\"p1\"], 3),\n",
    "        \"r1\": round(best[\"r1\"], 3),\n",
    "        \"objective\": round(best[\"objective\"], 3),\n",
    "        \"pass_50_50\": best[\"passed\"]\n",
    "    }\n",
    "    return row, pipe, best\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 10 — DEFINE THE REQUIRED MODELS\n",
    "# Purpose: Create the 4 required supervised learning models\n",
    "# ============================================================\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=6000, class_weight=\"balanced\"),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=75, weights=\"distance\"),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=600,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced_subsample\"\n",
    "    ),\n",
    "    \"SVC (Calibrated LinearSVC)\": CalibratedClassifierCV(\n",
    "        estimator=LinearSVC(dual=\"auto\", max_iter=12000, class_weight=\"balanced\"),\n",
    "        method=\"sigmoid\",\n",
    "        cv=3\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 11 — TRAIN + EVALUATE ALL MODELS + BUILD COMPARISON TABLE\n",
    "# Purpose: Run each model, store results, and choose a winner\n",
    "# ============================================================\n",
    "\n",
    "rows = []\n",
    "fitted = {}\n",
    "bestinfo = {}\n",
    "\n",
    "for name, est in models.items():\n",
    "    row, pipe, best = evaluate_model(name, est)\n",
    "    rows.append(row)\n",
    "    fitted[name] = pipe\n",
    "    bestinfo[name] = best\n",
    "\n",
    "final = pd.DataFrame(rows).sort_values(\n",
    "    by=[\"pass_50_50\", \"objective\", \"auc\"],\n",
    "    ascending=[False, False, False]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"#\"*78)\n",
    "print(\"FINAL COMPARISON (PASS first, then objective, then AUC)\")\n",
    "print(\"#\"*78)\n",
    "print(final.to_string(index=False))\n",
    "\n",
    "winner = final.iloc[0][\"model\"]\n",
    "print(\"\\nWINNER:\", winner)\n",
    "print(\"Winner threshold:\", final.iloc[0][\"thr\"])\n",
    "print(\"Winner PASS 50/50?:\", final.iloc[0][\"pass_50_50\"])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 12 — SAMPLE PREDICTIONS FOR THE WINNER\n",
    "# Purpose: Show example outputs (probability + predicted class)\n",
    "# ============================================================\n",
    "\n",
    "pipe_winner = fitted[winner]\n",
    "thr_winner = bestinfo[winner][\"threshold\"]\n",
    "\n",
    "scores_w = get_scores(pipe_winner, X_test)\n",
    "preds_w = (scores_w >= thr_winner).astype(int)\n",
    "\n",
    "pred_table = X_test.copy()\n",
    "pred_table[\"actual_high_risk\"] = y_test.values\n",
    "pred_table[\"pred_prob_high_risk\"] = scores_w\n",
    "pred_table[\"pred_high_risk\"] = preds_w\n",
    "\n",
    "print(\"\\nSample prediction outputs (winner):\")\n",
    "print(pred_table[[\"pred_prob_high_risk\",\"pred_high_risk\",\"actual_high_risk\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea1c8a-dca3-4f27-bdd9-ca7d7ed34cb0",
   "metadata": {},
   "source": [
    "RESULTS SUMMARY:\n",
    "- Dataset: 50,000 rows sampled (grade-stratified) from 396,030 total.\n",
    "- Target definition: high_risk=1 for grades D/E/F/G, high_risk=0 for grades A/B/C.\n",
    "- High-risk rate: 27.7%.\n",
    "\n",
    "Model comparison used:\n",
    "- ROC-AUC for ranking quality of probability scores\n",
    "- Exhaustive threshold scan (0.05 to 0.95) to find the best decision threshold\n",
    "- Rubric requirement: Precision >= 0.50 and Recall >= 0.50 for both classes\n",
    "\n",
    "Winner: Logistic Regression\n",
    "- ROC-AUC: 0.8945\n",
    "- Best threshold: 0.60\n",
    "- Low-risk (0): precision=0.887, recall=0.888\n",
    "- High-risk (1): precision=0.707, recall=0.704\n",
    "- Objective (min of the four metrics): 0.704 → PASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb0821c-6041-4d80-a172-d5c443dd9d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
